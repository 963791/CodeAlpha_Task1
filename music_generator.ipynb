{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udfbc AI Music Generator Using Classical MIDI (Internship Task)\n", "This notebook builds an LSTM-based model to generate classical music using MIDI files.\n", "- Dataset: [Classical Music MIDI Dataset on Kaggle](https://www.kaggle.com/datasets/soumikrakshit/classical-music-midi)\n", "- Libraries: music21, Keras, TensorFlow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udee0\ufe0f Install Required Libraries\n", "!pip install music21 keras tensorflow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udcc1 Import Libraries\n", "import os\n", "import numpy as np\n", "from music21 import converter, instrument, note, chord, stream\n", "from keras.models import Sequential\n", "from keras.layers import LSTM, Dropout, Dense, Activation\n", "from keras.utils import to_categorical"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce5 Extract Notes from MIDI\n", "def extract_notes_from_midi(midi_dir):\n", "    notes = []\n", "    for file in os.listdir(midi_dir):\n", "        if file.endswith('.mid'):\n", "            try:\n", "                midi = converter.parse(os.path.join(midi_dir, file))\n", "                parts = instrument.partitionByInstrument(midi)\n", "                elements = parts.parts[0].recurse() if parts else midi.flat.notes\n", "                for element in elements:\n", "                    if isinstance(element, note.Note):\n", "                        notes.append(str(element.pitch))\n", "                    elif isinstance(element, chord.Chord):\n", "                        notes.append('.'.join(str(n) for n in element.normalOrder))\n", "            except Exception as e:\n", "                print(f\"Error parsing {file}: {e}\")\n", "    return notes\n", "\n", "# Replace with your actual path to the MIDI folder\n", "midi_folder = './classical-music-midi/MIDI'\n", "notes = extract_notes_from_midi(midi_folder)\n", "print(f\"Total notes extracted: {len(notes)}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udd22 Prepare Sequences\n", "sequence_length = 100\n", "pitch_names = sorted(set(notes))\n", "note_to_int = {note: number for number, note in enumerate(pitch_names)}\n", "\n", "network_input = []\n", "network_output = []\n", "\n", "for i in range(len(notes) - sequence_length):\n", "    seq_in = notes[i:i + sequence_length]\n", "    seq_out = notes[i + sequence_length]\n", "    network_input.append([note_to_int[n] for n in seq_in])\n", "    network_output.append(note_to_int[seq_out])\n", "\n", "n_patterns = len(network_input)\n", "n_vocab = len(pitch_names)\n", "\n", "X = np.reshape(network_input, (n_patterns, sequence_length, 1)) / float(n_vocab)\n", "y = to_categorical(network_output)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83e\udde0 Build the LSTM Model\n", "model = Sequential()\n", "model.add(LSTM(512, return_sequences=True, input_shape=(X.shape[1], 1)))\n", "model.add(Dropout(0.3))\n", "model.add(LSTM(512))\n", "model.add(Dense(256))\n", "model.add(Dropout(0.3))\n", "model.add(Dense(n_vocab))\n", "model.add(Activation('softmax'))\n", "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n", "model.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\ude80 Train the Model\n", "model.fit(X, y, epochs=50, batch_size=64)\n", "# model.save('music_model.h5')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83c\udfb6 Generate Music\n", "int_to_note = {number: note for note, number in note_to_int.items()}\n", "start = np.random.randint(0, len(network_input) - 1)\n", "pattern = network_input[start]\n", "generated_notes = []\n", "\n", "for note_index in range(500):\n", "    input_seq = np.reshape(pattern, (1, len(pattern), 1)) / float(n_vocab)\n", "    prediction = model.predict(input_seq, verbose=0)\n", "    index = np.argmax(prediction)\n", "    result = int_to_note[index]\n", "    generated_notes.append(result)\n", "    pattern.append(index)\n", "    pattern = pattern[1:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udcbe Convert to MIDI and Save\n", "def create_midi(prediction_output, filename=\"output.mid\"):\n", "    output_notes = []\n", "    for pattern in prediction_output:\n", "        if '.' in pattern or pattern.isdigit():\n", "            notes_in_chord = [note.Note(int(n)) for n in pattern.split('.')]\n", "            new_chord = chord.Chord(notes_in_chord)\n", "            output_notes.append(new_chord)\n", "        else:\n", "            new_note = note.Note(pattern)\n", "            output_notes.append(new_note)\n", "    midi_stream = stream.Stream(output_notes)\n", "    midi_stream.write('midi', fp=filename)\n", "\n", "create_midi(generated_notes, \"generated_classical.mid\")\n", "print(\"\u2705 MIDI File Saved: generated_classical.mid\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}